---
title: "Highlight results, don’t hide them: Enhance interpretation, reduce biases and improve reproducibility"

date: 07/01/23
authors_string: Paul Taylor, Richard Reynolds, Vince Calhoun, Javier Gonzalez-Castillo, Daniel Handwerker, Peter Bandettini, Amanda Mejia, Gang Chen
authors:
   - Paul Taylor
   - Richard Reynolds
   - Vince Calhoun
   - Javier Gonzalez-Castillo
   - Daniel Handwerker
   - Peter Bandettini
   - Amanda Mejia
   - Gang Chen
author_ids:
   - peter_bandettini
   - javier_gonzalezcastillo
   - dan_handwerker
journal: 'NeuroImage'
volume: 274.0
issue: 
pages: 120138
book_title: ''
publisher: ''
isbn: 
abstract: 'Most neuroimaging studies display results that represent only a tiny fraction of the collected data. While it is conventional to present &quot;only the significant results&quot; to the reader, here we suggest that this practice has several negative consequences for both reproducibility and understanding. This practice hides away most of the results of the dataset and leads to problems of selection bias and irreproducibility, both of which have been recognized as major issues in neuroimaging studies recently. Opaque, all-or-nothing thresholding, even if well-intentioned, places undue influence on arbitrary filter values, hinders clear communication of scientific results, wastes data, is antithetical to good scientific practice, and leads to conceptual inconsistencies. It is also inconsistent with the properties of the acquired data and the underlying biology being studied. Instead of presenting only a few statistically significant locations and hiding away the remaining results, studies should &quot;highlight&quot; the former while also showing as much as possible of the rest. This is distinct from but complementary to utilizing data sharing repositories: the initial presentation of results has an enormous impact on the interpretation of a study. We present practical examples and extensions of this approach for voxelwise, regionwise and cross-study analyses using publicly available data that was analyzed previously by 70 teams (NARPS; Botvinik-Nezer, et al., 2020), showing that it is possible to balance the goals of displaying a full set of results with providing the reader reasonably concise and &quot;digestible&quot; findings. In particular, the highlighting approach sheds useful light on the kind of variability present among the NARPS teams’ results, which is primarily a varied strength of agreement rather than disagreement. Using a meta-analysis built on the informative &quot;highlighting&quot; approach shows this relative agreement, while one using the standard &quot;hiding&quot; approach does not. We describe how this simple but powerful change in practice—focusing on highlighting results, rather than hiding all but the strongest ones—can help address many large concerns within the field, or at least to provide more complete information about them. We include a list of practical suggestions for results reporting to improve reproducibility, cross-study comparisons and meta-analyses.'
project_id: education
paper_url: https://www.sciencedirect.com/science/article/pii/S1053811923002896?via%3Dihub
doi: 10.1016/j.neuroimage.2023.120138
data_loc: 'https://pubmed.ncbi.nlm.nih.gov/32483374/'
code_loc: 'https://github.com/afni/apaper_highlight_narps'
file: '/assets/publications/'
file_name: ''
type: journal_article
layout: publication 
---